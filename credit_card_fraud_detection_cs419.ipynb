{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fr_ZudxWjSVG"
   },
   "source": [
    "# Credit Card Fraud Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQkrsS1VjSVL"
   },
   "source": [
    "# 1. Introduction\n",
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMHsDUhAjSVM"
   },
   "source": [
    "We use a dataset of credit card transactions made over a two-day period in September 2013 by European cardholders. The dataset contains 284,807 transactions, of which 492 (0.17%) are fraudulent.\n",
    "\n",
    "Each transaction has 30 features, all of which are numerical. The features `V1, V2, ..., V28` are the result of a PCA transformation. To protect confidentiality, background information on these features is not available. The `Time` feature contains the time elapsed since the first transaction, and the `Amount` feature contains the transaction amount. The response variable, `Class`, is 1 in the case of fraud, and 0 otherwise.\n",
    "\n",
    "Our goal in this project is to construct models to predict whether a credit card transaction is fraudulent. We'll attempt a supervised learning approach. We'll also create visualizations to help us understand the structure of the data and unearth any interesting patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrY3OlUhjSVN"
   },
   "source": [
    "# 2. Data Analysis\n",
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YJnYcaXjSVN"
   },
   "source": [
    "Import basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v1vVdhYdjSVO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('display.max_colwidth', 1000, 'display.max_rows', None, 'display.max_columns', None)\n",
    "\n",
    "# Plotting options\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jknaERsjSVP"
   },
   "source": [
    "Read in the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzphHP2IkbEw",
    "outputId": "3d3264c6-02d5-4a98-f3f2-a1566b6ffdca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!gdown 1c2a2xgV47ijS7xH0TgPwPAdTZBQ605sP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1c2a2xgV47ijS7xH0TgPwPAdTZBQ605sP \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = '1c2a2xgV47ijS7xH0TgPwPAdTZBQ605sP'\n",
    "\n",
    "# URL to download the file\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Output file name\n",
    "output_file = 'creditcard.csv'  # Specify the desired file extension\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output_file, quiet=False)  # Set quiet=True to suppress output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0ZSnEpepjSVP"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/creditcard.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transactions \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/creditcard.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\project1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\project1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\project1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\project1\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\project1\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/creditcard.csv'"
     ]
    }
   ],
   "source": [
    "transactions = pd.read_csv('/content/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj3wkJdijSVP"
   },
   "source": [
    "Check basic metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CS9Va-ckjSVQ",
    "outputId": "34420413-be4c-435c-baae-f020e40327b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPDzlRprjSVQ",
    "outputId": "ee509497-2809-448e-81a8-e8cb0f6bcabc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku2JnmQtjSVR"
   },
   "source": [
    "viewing class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCVs05sijSVR",
    "outputId": "f98e914e-905b-4419-c1bb-f03324b21bc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0Df-mvkjSVS",
    "outputId": "3a77319a-7236-4234-ea8b-ee5469eef4a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cu3deQ4jSVS"
   },
   "source": [
    "Only 0.17% (492 out of 284,807) transactions are fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDEy8m66jSVS"
   },
   "source": [
    "# 3. Train/Test Split\n",
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybHNYPpEW0N6"
   },
   "source": [
    "## 3.1 Undersampling\n",
    "<a id='3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlXkIGEIW3KM"
   },
   "source": [
    "Build a sample dataset containing similar distribution of normal transactions and Fraudulent Transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCj3Dee7XB0F"
   },
   "source": [
    "Number of Fraudulent Transactions --> 492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rVRTOLpQyVtN"
   },
   "outputs": [],
   "source": [
    "legit = transactions[transactions.Class == 0]\n",
    "fraud = transactions[transactions.Class == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QtWT13mKWjJ_"
   },
   "outputs": [],
   "source": [
    "legit_sample = legit.sample(n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNiYI_SmXeim"
   },
   "source": [
    "Concatenating two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0yiXrYiRXcnE"
   },
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([legit_sample, fraud], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFsRcj0gX-3M",
    "outputId": "36fa1849-30f1-4ac3-957d-9be241b8b6f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "jan1xMeWYLrM",
    "outputId": "fc6018ee-b015-4ad4-8fc8-6006113da9c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3881a09a-a6ae-4855-86dd-eea9408d468b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94684.840120</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>-0.005912</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>-0.009291</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>0.010758</td>\n",
       "      <td>-0.009876</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>-0.006096</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>-0.000979</td>\n",
       "      <td>-0.001494</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>88.531656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>-5.676883</td>\n",
       "      <td>3.800173</td>\n",
       "      <td>-6.259393</td>\n",
       "      <td>-0.109334</td>\n",
       "      <td>-6.971723</td>\n",
       "      <td>-0.092929</td>\n",
       "      <td>-4.139946</td>\n",
       "      <td>-6.665836</td>\n",
       "      <td>-2.246308</td>\n",
       "      <td>0.680659</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3881a09a-a6ae-4855-86dd-eea9408d468b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3881a09a-a6ae-4855-86dd-eea9408d468b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3881a09a-a6ae-4855-86dd-eea9408d468b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      94684.840120  0.007943 -0.005912  0.014920 -0.009291  0.004970   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9       V10       V11       V12  \\\n",
       "Class                                                                         \n",
       "0     -0.000108  0.011054 -0.000490 -0.001861  0.010758 -0.009876  0.012303   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123 -5.676883  3.800173 -6.259393   \n",
       "\n",
       "            V13       V14       V15       V16       V17       V18       V19  \\\n",
       "Class                                                                         \n",
       "0     -0.006096  0.009838 -0.000003  0.009235  0.011778 -0.000133  0.001286   \n",
       "1     -0.109334 -6.971723 -0.092929 -4.139946 -6.665836 -2.246308  0.680659   \n",
       "\n",
       "            V20       V21       V22       V23       V24       V25       V26  \\\n",
       "Class                                                                         \n",
       "0     -0.000278 -0.000979 -0.001494 -0.000279 -0.001035 -0.001618 -0.000296   \n",
       "1      0.372319  0.713588  0.014049 -0.040308 -0.105130  0.041449  0.051648   \n",
       "\n",
       "            V27       V28      Amount  \n",
       "Class                                  \n",
       "0     -0.001370 -0.000316   88.531656  \n",
       "1      0.170575  0.075667  122.211321  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBrDMgXcjSVS"
   },
   "source": [
    "Before we begin preprocessing, we split off a test data set. First split the data into features and response variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "JZHR6p3wjSVS"
   },
   "outputs": [],
   "source": [
    "X = new_dataset.drop(labels='Class', axis=1) # Features\n",
    "y = new_dataset.loc[:,'Class']               # Response\n",
    "del new_dataset                              # Delete the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDfF8z2tjSVS"
   },
   "source": [
    "We'll use a test size of 20%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "id": "Cwc7xLjfjSVT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "id": "_iEGU_n7jSVT"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O95ss4-ajSVT",
    "outputId": "06e85328-c3da-447b-a6d3-dae9644986ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80393, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsYxiFx8jSVT",
    "outputId": "b2bc0d74-849d-4b53-e059-a19181d55597"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20099, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SSlEuk7IjSVT"
   },
   "outputs": [],
   "source": [
    "# Prevent view warnings\n",
    "X_train.is_copy = False\n",
    "X_test.is_copy = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAlnBHrFvCp9"
   },
   "source": [
    "## 3.1 Upsampling using SMOTE\n",
    "<a id='3.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0A4_W7MIvCau"
   },
   "outputs": [],
   "source": [
    "def resamplingDataPrep(X_train, y_train, target_var): \n",
    "    # concatenate our training data back together\n",
    "    resampling = X_train.copy()\n",
    "    resampling[target_var] = y_train.values\n",
    "    # separate minority and majority classes\n",
    "    majority_class = resampling[resampling[target_var]==0]\n",
    "    minority_class = resampling[resampling[target_var]==1]\n",
    "    # Get a class count to understand the class imbalance.\n",
    "    print('majority_class: '+ str(len(majority_class)))\n",
    "    print('minority_class: '+ str(len(minority_class)))\n",
    "    return majority_class, minority_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVW1rFNTvIxO",
    "outputId": "ca3d8157-81ed-4e35-c7d3-859c698f55f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_class: 79999\n",
      "minority_class: 394\n"
     ]
    }
   ],
   "source": [
    "maj, min = resamplingDataPrep(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VbqH8I8hwgm2"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UAc5cE9NwJ8m"
   },
   "outputs": [],
   "source": [
    "def upsample_SMOTE(X_train, y_train, ratio=1.0):\n",
    "    \"\"\"Upsamples minority class using SMOTE.\n",
    "    Ratio argument is the percentage of the upsampled minority class in relation\n",
    "    to the majority class. Default is 1.0\n",
    "    \"\"\"\n",
    "    sm = SMOTE(random_state=23, sampling_strategy=ratio)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    #print(len(X_train_sm))\n",
    "    resampling = X_train_sm.copy()\n",
    "    target_var = 0;\n",
    "    resampling[target_var] = y_train_sm.values\n",
    "    # separate minority and majority classes\n",
    "    majority_class = resampling[resampling[target_var]==0]\n",
    "    minority_class = resampling[resampling[target_var]==1]\n",
    "    # Get a class count to understand the class imbalance.\n",
    "    print('majority_class: '+ str(len(majority_class)))\n",
    "    print('minority_class: '+ str(len(minority_class)))\n",
    "    return X_train_sm, y_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zGR1rV_wKcJ",
    "outputId": "0d20a5d7-4f43-4df5-83fc-a3d877b97e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority_class: 79999\n",
      "minority_class: 79999\n"
     ]
    }
   ],
   "source": [
    "X_train_sm, y_train_sm = upsample_SMOTE(X_train, y_train, ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJRgy3Otuls8"
   },
   "source": [
    "### Final distribution in train set:\n",
    "80,000 normal and fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "a0uM-zZ-0Or0"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X_train_sm, y_train_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxIl2mhKjSVj"
   },
   "source": [
    "# 4. Mutual Information between Fraud and the Predictors\n",
    "<a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7G_cmKZjSVj"
   },
   "source": [
    "[Mutual information](https://en.wikipedia.org/wiki/Mutual_information) is a non-parametric method to estimate the mutual dependence between two variables. Mutual information of 0 indicates no dependence, and higher values indicate higher dependence. According to the [sklearn User Guide](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection), \"mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation.\" We have 227,845 training samples, so mutual information should work well. Because the target variable is discrete, we use [`mutual_info_classif`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif) (as opposed to [`mutual_info_regression`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression) for a continuous target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "W--gBZWzjSVj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8oUy7L1zjSVk"
   },
   "outputs": [],
   "source": [
    "mutual_infos = pd.Series(data=mutual_info_classif(X_train, y_train, discrete_features=False, random_state=1), index=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbMDVWM_jSVk"
   },
   "source": [
    "The calculated mutual informations of each variable with `Class`, in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfNdBzLNjSVk",
    "outputId": "1483a788-b3bd-41b7-d121-42a7158ee58b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14       0.531440\n",
       "V10       0.465248\n",
       "V12       0.464279\n",
       "V4        0.441128\n",
       "V17       0.441111\n",
       "V11       0.415013\n",
       "V3        0.394386\n",
       "V16       0.352956\n",
       "V7        0.329546\n",
       "Amount    0.318155\n",
       "V2        0.292301\n",
       "V9        0.279042\n",
       "V27       0.251656\n",
       "Time      0.248493\n",
       "V21       0.244110\n",
       "V1        0.228429\n",
       "V18       0.207154\n",
       "V6        0.196228\n",
       "V28       0.179425\n",
       "V8        0.172210\n",
       "V5        0.155805\n",
       "V20       0.120983\n",
       "V19       0.106473\n",
       "V24       0.067919\n",
       "V23       0.060694\n",
       "V26       0.056855\n",
       "V25       0.034999\n",
       "V22       0.032365\n",
       "V15       0.025263\n",
       "V13       0.024378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_infos.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jABD_Bk9jSVk"
   },
   "source": [
    "The five most correlated variables with `Class` are, in decreasing order, V17, V14, V10, V12, and V11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkU8_BdmjSVp"
   },
   "source": [
    "# 5. Evaluation method\n",
    "<a id='5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "id": "yj_rgvU6jSVp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "id": "1rLwwIIijSVp"
   },
   "outputs": [],
   "source": [
    "def classification_eval(estimator, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Print several metrics of classification performance of an estimator, given features X_test and true labels y_test.\n",
    "    \n",
    "    Input: estimator or GridSearchCV instance, X_test, y_test\n",
    "    Returns: text printout of metrics\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    # Number of decimal places based on number of samples\n",
    "    dec = np.int64(np.ceil(np.log10(len(y_test))))\n",
    "    \n",
    "    print('CONFUSION MATRIX')\n",
    "    print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "    \n",
    "    print('CLASSIFICATION REPORT')\n",
    "    print(classification_report(y_test, y_pred, digits=dec))\n",
    "    \n",
    "    print('SCALAR METRICS')\n",
    "    format_str = '%%13s = %%.%if' % dec\n",
    "    print(format_str % ('MCC', matthews_corrcoef(y_test, y_pred)))\n",
    "    if y_test.nunique() <= 2: # Additional metrics for binary classification\n",
    "        try:\n",
    "            y_score = estimator.predict_proba(X_test)[:,1]\n",
    "        except:\n",
    "            y_score = estimator.decision_function(X_test)\n",
    "        print(format_str % ('AUPRC', average_precision_score(y_test, y_score)))\n",
    "        print(format_str % ('AUROC', roc_auc_score(y_test, y_score)))\n",
    "    print(format_str % (\"Cohen's kappa\", cohen_kappa_score(y_test, y_pred)))\n",
    "    print(format_str % ('Accuracy', accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfLKGOO4jSVq"
   },
   "source": [
    "According to the MCC, the random forest performed better on the test set than on the training set. This is probably due to the refit model being trained on the entire training data set, and not on the smaller CV folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKWXPEcRjSVk"
   },
   "source": [
    "# 6. Modeling\n",
    "<a id='6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlU8s3WVjSVk"
   },
   "source": [
    "The following models are trained\n",
    "* Logistic regression\n",
    "* Support vector classifier\n",
    "* Random forest\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l_F88g8jSVk"
   },
   "source": [
    "## 6.1 Logistic Regression and Support Vector Classifier\n",
    "<a id='6.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeLSLje0jSVl"
   },
   "source": [
    "The class [`SGDClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) implements multiple linear classifiers with SGD training, which makes learning much faster on large datasets. We'll implement the model as a machine learning pipeline that includes [`StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) for data standardization (rescaling each variable to zero mean and unit variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "A93SA4JgjSVl"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "eXCsuDOojSVl"
   },
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline([\n",
    "    ('scaler', StandardScaler(copy=False)),\n",
    "    ('model', SGDClassifier(max_iter=1000, tol=1e-3, random_state=1, warm_start=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJmDYC4ZjSVl"
   },
   "source": [
    "We'll conduct a grid search over several hyperparameter choices. The search uses 5-fold cross-validation with stratified folds. The type of linear classifier is chosen with the `loss` hyperparameter. For a linear SVC we set `loss = 'hinge'`, and for logistic regression we set `loss = 'log'`.\n",
    "\n",
    "Set the hyperparameter grids to search over, one grid for the linear SVC and one for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "F8X6X03-jSVl"
   },
   "outputs": [],
   "source": [
    "param_grid_sgd = [{\n",
    "    'model__loss': ['log'],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__alpha': np.logspace(start=-3, stop=3, num=20)\n",
    "}, {\n",
    "    'model__loss': ['hinge'],\n",
    "    'model__alpha': np.logspace(start=-3, stop=3, num=20),\n",
    "    'model__class_weight': [None, 'balanced']\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbvje9AajSVl"
   },
   "source": [
    "The grid search, implemented by [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), uses [`StratifiedKFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) with 5 folds for the train/validation splits. We'll use [`matthews_corrcoef`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) (the [Matthews correlation coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient), MCC) as our scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "id": "xsqahEZzjSVl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "JUlbQgExjSVm"
   },
   "outputs": [],
   "source": [
    "MCC_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_sgd = GridSearchCV(estimator=pipeline_sgd, param_grid=param_grid_sgd, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueUkAkPUjSVm"
   },
   "source": [
    "Perform the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PohERgQjSVm",
    "outputId": "0dffa644-58c3-4252-d647-2f57196914bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings(): # Suppress warnings from the matthews_corrcoef function\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    grid_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in8TqG-5jSVm"
   },
   "source": [
    "Mean cross-validated MCC score of the best estimator found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LS7rhuwjSVm",
    "outputId": "4d3ef32a-a1b2-48b3-d2d7-c7472d49336f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590021961840508"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sgd.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2Izj9aQjSVm"
   },
   "source": [
    "This is a pretty good MCC score---random guessing has a score of 0, and a perfect predictor has a score of 1. Now check the best hyperparameters found in the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzIF4TPmjSVm",
    "outputId": "c36fb940-aba7-45c5-eb92-b59b98c01283"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.001, 'model__loss': 'log', 'model__penalty': 'l1'}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sgd.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvN_sTcJjSVn"
   },
   "source": [
    "So the linear SVC performed better than logistic regression, and with a high level of regularization ($\\alpha\\approx 483$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrXK541TI5vo",
    "outputId": "adacacb4-af47-4fbb-db1b-613d84c76a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "[[19797   204]\n",
      " [    9    89]] \n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99955   0.98980   0.99465     20001\n",
      "           1    0.30375   0.90816   0.45524        98\n",
      "\n",
      "    accuracy                        0.98940     20099\n",
      "   macro avg    0.65165   0.94898   0.72495     20099\n",
      "weighted avg    0.99615   0.98940   0.99202     20099\n",
      "\n",
      "SCALAR METRICS\n",
      "          MCC = 0.52187\n",
      "        AUPRC = 0.84508\n",
      "        AUROC = 0.96483\n",
      "Cohen's kappa = 0.45123\n",
      "     Accuracy = 0.98940\n"
     ]
    }
   ],
   "source": [
    "classification_eval(grid_sgd, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prUrmdmEjSVn"
   },
   "source": [
    "## 6.2 Random Forest\n",
    "<a id='6.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwBNObWdjSVn"
   },
   "source": [
    "Next we'll try a random forest model, implemented in [`RandomForestClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "yshTGBoEjSVn"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUgavbnjjSVn"
   },
   "source": [
    "We do not need to rescale the data for tree-based models, so our pipeline will simply consist of the random forest model. We'll leave the pipeline implementation in place in case we want to add preprocessing steps in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ExZdXspmjSVn"
   },
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdeVivL7jSVn"
   },
   "source": [
    "The random forest takes much longer to train on this fairly large dataset, so we don't actually do a hyperparameter grid search, only specifiying the number of estimators. We'll leave the grid search implemented in case we decide to try different hyperparameter values in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "75C2ZT4XjSVo"
   },
   "outputs": [],
   "source": [
    "param_grid_rf = {'model__n_estimators': [75]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "juKod3Z0jSVo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "MCC_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_rf = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uB91INVjSVo"
   },
   "source": [
    "Perform the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guaCTJtUjSVo",
    "outputId": "13c590b4-35ab-4a59-eabe-b54fdbc34a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model',\n",
       "                                        RandomForestClassifier(n_jobs=-1,\n",
       "                                                               random_state=1))]),\n",
       "             n_jobs=-1, param_grid={'model__n_estimators': [75]},\n",
       "             scoring=make_scorer(matthews_corrcoef), verbose=1)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBmiEmixjSVo",
    "outputId": "d671161d-aace-42c1-d4a7-759b5470e264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994500956412578"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfqASb_UjSVp"
   },
   "source": [
    "The random forest performed much better than the linear SVC---and without any hyperparameter tweaking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNBa_Q1TjSVp",
    "outputId": "fdc6d174-8a3c-4555-8526-21665b3805e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': 75}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVkTl5a7jSVq",
    "outputId": "55c0d027-fea4-4c10-8b1b-4c9a5bc5519f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "[[19994     7]\n",
      " [   13    85]] \n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99935   0.99965   0.99950     20001\n",
      "           1    0.92391   0.86735   0.89474        98\n",
      "\n",
      "    accuracy                        0.99900     20099\n",
      "   macro avg    0.96163   0.93350   0.94712     20099\n",
      "weighted avg    0.99898   0.99900   0.99899     20099\n",
      "\n",
      "SCALAR METRICS\n",
      "          MCC = 0.89469\n",
      "        AUPRC = 0.89078\n",
      "        AUROC = 0.97938\n",
      "Cohen's kappa = 0.89424\n",
      "     Accuracy = 0.99900\n"
     ]
    }
   ],
   "source": [
    "classification_eval(grid_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jem5TJ1Ff_QV"
   },
   "source": [
    "## 6.3 Decision Tree\n",
    "<a id='6.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OGSAXBquYf3d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03baTAFoZMOU",
    "outputId": "97799dc5-3a03-47ba-dd82-b58d01368e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 10]},\n",
       "             scoring=make_scorer(matthews_corrcoef), verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCC_scorer = make_scorer(matthews_corrcoef)\n",
    "params = {'criterion':['gini','entropy'],'max_depth':[4,10]}\n",
    "grid_search_cv = GridSearchCV(estimator=DecisionTreeClassifier(random_state=1), param_grid=params, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61Sd3zi77uy9",
    "outputId": "0ece9366-7cf7-46d2-f408-c7a43bf65776"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833975545664597"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i13TLhnW8ARs",
    "outputId": "78e79164-b2c3-44ca-e9c8-c8214cc39ced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 10}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QZUZd1Ig_CO",
    "outputId": "97eb6b4b-b51e-40b4-82ab-1bd8d0a8ce22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "[[19819   182]\n",
      " [   10    88]] \n",
      "\n",
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99950   0.99090   0.99518     20001\n",
      "           1    0.32593   0.89796   0.47826        98\n",
      "\n",
      "    accuracy                        0.99045     20099\n",
      "   macro avg    0.66271   0.94443   0.73672     20099\n",
      "weighted avg    0.99621   0.99045   0.99266     20099\n",
      "\n",
      "SCALAR METRICS\n",
      "          MCC = 0.53782\n",
      "        AUPRC = 0.65611\n",
      "        AUROC = 0.94032\n",
      "Cohen's kappa = 0.47450\n",
      "     Accuracy = 0.99045\n"
     ]
    }
   ],
   "source": [
    "classification_eval(grid_search_cv, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njn_JaS8jSVq"
   },
   "source": [
    "# 7. Conclusion\n",
    "<a id='7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bm0LHs9hjSVq"
   },
   "source": [
    "We were able to accurately identify fraudulent credit card transactions using a random forest model. We found that the five variables most correlated with fraud are, in decreasing order, V17, V14, V10, V12, and V11. \n",
    "\n",
    "We used the [Matthews correlation coefficient (MCC)](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient) to compare the performance of different models. In cross validation, the best linear model (logistic regression, linear SVC) achieved a cross-validated MCC score of 0.52, decision tree achieved mcc score of 0.53, and a random forest achieved a cross-validated MCC score of 0.89. We therefore chose the random forest as the better model, which obtained an MCC of 0.89 on the test set.\n",
    "\n",
    "To improve a chosen model, we searched over a grid of hyperparameters and compared performance with cross-validation. It may be possible to improve the random forest model by further tweaking the hyperparameters, given additional time and/or computational power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaWYOvbwuF7J"
   },
   "source": [
    "References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du6LR2FduIRQ"
   },
   "source": [
    "* [Kaggle Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
    "* [sklearn](https://scikit-learn.org/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "credit_card_fraud_detection_cs419",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
